# InterviewAvatar

An open-source AI-powered interview agent that acts as your digital clone for Zoom job interviews. Uses your voice, face, and expertise to answer questions in real-time.

![InterviewAvatar Demo](docs/demo.gif)

## Features

- ðŸ§  **Multi-LLM Support**: Ollama (local), OpenAI, Claude
- ðŸ“š **RAG Pipeline**: Upload your resume/experience for context-aware answers
- ðŸŽ¤ **Voice Cloning**: ElevenLabs integration for natural speech
- ðŸ‘¤ **Live Avatar**: HeyGen streaming for real-time video
- ðŸŽ¥ **Zoom Integration**: OBS virtual camera + audio routing
- âš¡ **Real-time**: <5s end-to-end latency (question â†’ video response)

## Quick Start

### Prerequisites
- Node.js 18+
- (Optional) Ollama for local LLM
- (Optional) OBS Studio for Zoom integration

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/interview-avatar.git
cd interview-avatar

# Install dependencies
npm install

# Configure environment
cp .env.example .env.local
# Edit .env.local with your API keys

# Run development server
npm run dev
```

Open [http://localhost:3000](http://localhost:3000)

### Docker (Recommended)

```bash
# Start all services
docker-compose up -d

# Access at http://localhost:3000
```

## Usage

### 1. Configure LLM
- Go to Settings â†’ Select your LLM provider
- **Local**: Install Ollama + DeepSeek R1
- **Cloud**: Add OpenAI or Anthropic API key

### 2. Upload Your Experience
- Go to Setup â†’ RAG
- Upload resume, past interview answers, project descriptions
- System will use this context for answers

### 3. Practice Mode
- Go to Practice
- Select a question
- Generate AI response
- Click "Speak Response" to hear it

### 4. Live Interview Mode
- Go to Live
- Start avatar session
- Type or generate responses
- Avatar speaks with lip-sync

### 5. Zoom Integration
- Install OBS Studio
- Follow [OBS Setup Guide](docs/obs-setup.md)
- Configure audio routing (see [Audio Setup](docs/audio-setup.md))
- Use OBS Virtual Camera in Zoom

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Question                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM (Ollama/OpenAI/Claude) + RAG                           â”‚
â”‚  â†’ Generates contextual answer                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Voice Synthesis (ElevenLabs)                               â”‚
â”‚  â†’ Converts text to speech                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Video Avatar (HeyGen Streaming)                            â”‚
â”‚  â†’ Lip-synced video via WebRTC                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OBS Virtual Camera â†’ Zoom                                  â”‚
â”‚  â†’ Appears as your camera in meetings                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Documentation

- [Testing Guide](docs/testing.md) - How to test each component
- [OBS Setup](docs/obs-setup.md) - Configure virtual camera
- [Audio Setup](docs/audio-setup.md) - Route audio to Zoom
- [Deployment](docs/deployment.md) - Production deployment
- [API Reference](docs/api-reference.md) - REST API documentation
- [Configuration](docs/configuration.md) - Environment variables

## Tech Stack

- **Frontend**: Next.js 16, TypeScript, Tailwind CSS
- **LLM**: Ollama (DeepSeek R1), OpenAI, Anthropic
- **Voice**: ElevenLabs
- **Video**: HeyGen Streaming API
- **RAG**: In-memory (ChromaDB planned)
- **Integration**: OBS WebSocket, BlackHole (audio)

## Performance

Target latencies:
- LLM Response: <3s
- Voice Synthesis: <2s
- Video Streaming: <1s
- **Total**: <5s (question â†’ video)

## Roadmap

- [x] Phase 1: Foundation (Next.js, UI, Config)
- [x] Phase 2: Text Generation (LLM + RAG)
- [x] Phase 3: Voice Synthesis
- [x] Phase 4: Video Avatar
- [x] Phase 5: OBS Integration
- [x] Phase 6: Deployment & Polish
- [ ] ChromaDB integration
- [ ] Local voice (OpenVoice)
- [ ] Local video (LivePortrait)
- [ ] Real-time transcription (Whisper)
- [ ] Session recording & playback
- [ ] Performance analytics

## Contributing

Contributions welcome! See [CONTRIBUTING.md](docs/contributing.md)

## License

MIT License - see [LICENSE](LICENSE)

## Disclaimer

This tool is for educational and practice purposes. Always disclose the use of AI assistance in actual job interviews where required by the employer.

## Support

- ðŸ“§ Email: your@email.com
- ðŸ’¬ Discord: [Join our community](https://discord.gg/yourlink)
- ðŸ› Issues: [GitHub Issues](https://github.com/yourusername/interview-avatar/issues)

## Acknowledgments

- [HeyGen](https://heygen.com) - Streaming avatar API
- [ElevenLabs](https://elevenlabs.io) - Voice synthesis
- [Ollama](https://ollama.ai) - Local LLM runtime
- [OBS Studio](https://obsproject.com) - Virtual camera

---

**Star â­ this repo if you find it useful!**
